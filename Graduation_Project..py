#!/usr/bin/env python
# coding: utf-8

# # Проект: "Промышленность"

# **Описание проекта:**
# 
# Чтобы оптимизировать производственные расходы, металлургический комбинат «Стальная птица» решил уменьшить потребление электроэнергии на этапе обработки стали. Для этого комбинату нужно контролировать температуру сплава. Для этого необходимо построить модель, которая будет её предсказывать. В свою очередь заказчик хочет использовать разработанную модель для имитации технологического процесса.

# **Цель проекта:**
# 
# Необходимо построить модель, которая будет предсказывать температуру сплава. По условию от заказчика:
# 1. Целевой признак: последняя измеренная температура.
# 2. Метрика оценки качества: МАЕ (не выше 6.8).

# **Описание данных для проекта:**
# 
# Заказчиком предоставлены данные, которые состоят из нескольких файлов, полученных из разных источников:
# 1. data_arc_new.csv — данные об электродах;
# 2. data_bulk_new.csv — данные о подаче сыпучих материалов (объём);
# 3. data_bulk_time_new.csv — данные о подаче сыпучих материалов (время);
# 4. data_gas_new.csv — данные о продувке сплава газом;
# 5. data_temp_new.csv — результаты измерения температуры;
# 6. data_wire_new.csv — данные о проволочных материалах (объём);
# 7. data_wire_time_new.csv — данные о проволочных материалах (время).
# 
# Для файла **data_arc_new.csv**:
# - key — номер партии;
# - Начало нагрева дугой — время начала нагрева;
# - Конец нагрева дугой — время окончания нагрева;
# - Активная мощность — значение активной мощности;
# - Реактивная мощность — значение реактивной мощности.
# 
# Для файла **data_bulk_new.csv**:
# - key — номер партии;
# - Bulk 1 … Bulk 15 — объём подаваемого материала.
# 
# Для файла **data_bulk_time_new.csv**:
# - key — номер партии;
# - Bulk 1 … Bulk 15 — время подачи материала.
# 
# Для файла **data_gas_new.csv**:
# - key — номер партии;
# - Газ 1 — объём подаваемого газа.
# 
# Для файла **data_temp_new.csv**:
# - key — номер партии;
# - Время замера — время замера;
# - Температура — значение температуры.
# 
# Для файла **data_wire_new.csv**:
# - key — номер партии;
# - Wire 1 … Wire 9 — объём подаваемых проволочных материалов.
# 
# Для файла **data_wire_time_new.csv**:
# - key — номер партии;
# - Wire 1 … Wire 9 — время подачи проволочных материалов.
# 
# **Примечание к файлам с данными:** Во всех файлах столбец *key* содержит номер партии. В файлах может быть несколько строк с одинаковым значением *key*: они соответствуют разным итерациям обработки.

# **План работы с проектом:**
# 1. Загрузка и изучение данных;
# 2. Исследовательский анализ и предобработка данных;
# 3. Объединение данных;
# 4. Исследовательский анализ и предобработка данных объединённого датафрейма;
# 5. Подготовка данных;
# 6. Обучение моделей машинного обучения;
# 7. Выбор лучшей модели и проверка её качества на тестовой выборке;
# 8. Формирование общего вывода и рекомендаций для заказчика.

# ## Загрузка и изучение данных

# In[168]:


# установим, необходимую библиотеку
get_ipython().system('pip install catboost')


# In[169]:


# установим необходимую библиотеку
get_ipython().system('pip install lightgbm')


# In[170]:


get_ipython().system('pip install shap')


# In[171]:


# загрузим стандартные библиотеки, необходимые для работы
import pandas as pd
import math
import sklearn
import numpy as np
from scipy import stats as st

# загрузим библиотеки для визуализации данных
import matplotlib.pyplot as plt 
import seaborn as sns
import shap

# загрузим модули, необходимые для работы
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import RandomizedSearchCV, KFold
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from catboost import CatBoostRegressor
from lightgbm import LGBMRegressor
from sklearn.dummy import DummyRegressor
import time
import warnings
warnings.filterwarnings('ignore')

# зададим константу
RANDOM_STATE = 250825


# ### Файл 'data_arc_new.csv': данные об электродах

# In[172]:


# загрузим данные из файла 'data_arc_new.csv' 
try:
    # локальный путь к файлу
    data_arc_new = pd.read_csv('C:/Users/Admin/OneDrive/Рабочий стол/ВП/data_arc_new.csv')
except:
    # путь к файлу в тренажере
    data_arc_new = pd.read_csv('/datasets/data_arc_new.csv')

# посмотрим первые 5 строк датафрема
data_arc_new.head()


# In[173]:


# посмотрим общую информацию о данных
data_arc_new.info()


# **Примечание:** По полученным результатам видно, что данные соответствуют описанию задачи, пропуски отсутствуют. Названия столбцов необходимо привести к общепринятому "змеиному" стилю, а также изменить тип данных в столбцах 'Начало нагрева дугой' и 'Конец нагрева дугой' на 'datetime' (сейчас указан некорректный тип данных). Первично можем заметить, что некоторые партии нагревают по несколько раз.

# ### Файл 'data_bulk_new.csv': данные о подаче сыпучих материалов (объём)

# In[174]:


# загрузим данные из файла 'data_bulk_new.csv' 
try:
    # локальный путь к файлу
    data_bulk_new = pd.read_csv('C:/Users/Admin/OneDrive/Рабочий стол/ВП/data_bulk_new.csv')
except:
    # путь к файлу в тренажере
    data_bulk_new = pd.read_csv('/datasets/data_bulk_new.csv')

# посмотрим первые 5 строк датафрема
data_bulk_new.head()


# In[175]:


# посмотрим общую информацию о данных
data_bulk_new.info()


# **Примечание:** По полученным результатам видно, что данные соответствуют описанию задачи, в каждом столбце с объемом подаваемого материала присутствуют пропуски. Названия столбцов необходимо привести к общепринятому "змеиному" стилю, тип данных во всех столбцах корректный. Также можем заметить, что у нас присутствует достаточно много пропущенных значений, однако, это те пропуски, когда во время производства материал не подавался, соответственно, это естественный процесс производства, а значит, что все присутствующие пропуски можно заметить на ноль.

# ### Файл 'data_bulk_time_new.csv': данные о подаче сыпучих материалов (время)

# In[176]:


# загрузим данные из файла 'data_bulk_time_new.csv' 
try:
    # локальный путь к файлу
    data_bulk_time_new = pd.read_csv('C:/Users/Admin/OneDrive/Рабочий стол/ВП/data_bulk_time_new.csv')
except:
    # путь к файлу в тренажере
    data_bulk_time_new = pd.read_csv('/datasets/data_bulk_time_new.csv')

# посмотрим первые 5 строк датафрема
data_bulk_time_new.head()


# In[177]:


# посмотрим общую информацию о данных
data_bulk_time_new.info()


# **Примечание:** По полученным результатам видно, что данные соответствуют описанию задачи, в каждом столбце со временем подаваемого материала присутствуют пропуски. Названия столбцов необходимо привести к общепринятому "змеиному" стилю, а тип данных привести к 'datetime' во всех столбцах, кроме 'key'. Данный датасет имеет только информации о времени подачи материалов, что по сути не оказывает сильного значения на исследование, поэтому, скорее всего не будем его использовать для решения поставленной задачи.

# ### Файл 'data_gas_new.csv': данные о продувке сплава газом

# In[178]:


# загрузим данные из файла 'data_gas_new.csv' 
try:
    # локальный путь к файлу
    data_gas_new = pd.read_csv('C:/Users/Admin/OneDrive/Рабочий стол/ВП/data_gas_new.csv')
except:
    # путь к файлу в тренажере
    data_gas_new = pd.read_csv('/datasets/data_gas_new.csv')

# посмотрим первые 5 строк датафрема
data_gas_new.head()


# In[179]:


# посмотрим общую информацию о данных
data_gas_new.info()


# **Примечание:** По полученным результатам видно, что данные соответствуют описанию задачи, пропуски отсутствуют. Названия столбцов необходимо привести к общепринятому "змеиному" стилю, тип данных во всех столбцах корректный.

# ### Файл 'data_temp_new.csv': результаты измерения температуры

# In[180]:


# загрузим данные из файла 'data_temp_new.csv' 
try:
    # локальный путь к файлу
    data_temp_new = pd.read_csv('C:/Users/Admin/OneDrive/Рабочий стол/ВП/data_temp_new.csv')
except:
    # путь к файлу в тренажере
    data_temp_new = pd.read_csv('/datasets/data_temp_new.csv')

# посмотрим первые 5 строк датафрема
data_temp_new.head()


# In[181]:


# посмотрим общую информацию о данных
data_temp_new.info()


# **Примечание:** По полученным результатам видно, что данные соответствуют описанию задачи, присутствуют пропуски в столбце 'Температура'. Названия столбцов необходимо привести к общепринятому "змеиному" стилю, необходимо поменять тип данных в столбце 'Время замера' на 'datetime'.

# ### Файл 'data_wire_new.csv': данные о проволочных материалах (объём)

# In[182]:


# загрузим данные из файла 'data_wire_new.csv' 
try:
    # локальный путь к файлу
    data_wire_new = pd.read_csv('C:/Users/Admin/OneDrive/Рабочий стол/ВП/data_wire_new.csv')
except:
    # путь к файлу в тренажере
    data_wire_new = pd.read_csv('/datasets/data_wire_new.csv')

# посмотрим первые 5 строк датафрема
data_wire_new.head()


# In[183]:


# посмотрим общую информацию о данных
data_wire_new.info()


# **Примечание:** По полученным результатам видно, что данные соответствуют описанию задачи, в каждом столбце с объемом проволочных материалов присутствуют пропуски. Названия столбцов необходимо привести к общепринятому "змеиному" стилю, тип данных во всех столбцах корректный. Также можем заметить, что у нас присутствует достаточно много пропущенных значений, однако, это те пропуски, когда во время производства проволочный материал не подавался, соответственно, это естественный процесс производства, а значит, что все присутствующие пропуски можно заметить на ноль.

# ### Файл 'data_wire_time_new.csv': данные о проволочных материалах (время)

# In[184]:


# загрузим данные из файла 'data_wire_time_new.csv' 
try:
    # локальный путь к файлу
    data_wire_time_new = pd.read_csv('C:/Users/Admin/OneDrive/Рабочий стол/ВП/data_wire_time_new.csv')
except:
    # путь к файлу в тренажере
    data_wire_time_new = pd.read_csv('/datasets/data_wire_time_new.csv')

# посмотрим первые 5 строк датафрема
data_wire_time_new.head()


# In[185]:


# посмотрим общую информацию о данных
data_wire_time_new.info()


# **Примечание:** По полученным результатам видно, что данные соответствуют описанию задачи, в каждом столбце со временем проволочного материала присутствуют пропуски. Названия столбцов необходимо привести к общепринятому "змеиному" стилю, а тип данных привести к 'datetime' во всех столбцах, кроме 'key'. Данный датасет имеет только информации о времени проволочных материалов, что по сути не оказывает сильного значения на исследование, поэтому, скорее всего не будем его использовать для решения поставленной задачи.

# **Обобщающий вывод этапа "Загрузка и изучение данных":**
# 1. Данные во всех семи таблицах соответствую описанию задачи.
# 2. В пяти из семитаблицах с данными в столбцах присутствуют пропуски, некоторые из которых необходимо обработать. Также в некоторых таблицах необходимо изменить тип данных некоторых столбцов.
# 3. Во всех таблицах необходимо привести названия столбцов к общепринятому "змеиному" стилю.
# 4. Также стоит отметить, что при первичном изучении данных было выяснено, что таблицы 'data_bulk_time_new' и 'data_wire_time_new' содержать информацию о времени подачи различных видов материалов. Эти данные не имеют ценности для дальнейшего анализа. Поэтому уже на первом этапе эти таблицы с данными будут отброшены и не будут использоваться при дальнейшей обработке и реализации проекта, что в том числе сократит время выполнения задачи.

# ## Исследовательский анализ и предобработка данных

# На данном этапе будут рассмотрены и обработаны следующие пять таблицы с данными:
# 1. data_arc_new — данные об электродах;
# 2. data_bulk_new — данные о подаче сыпучих материалов (объём);
# 3. data_gas_new — данные о продувке сплава газом;
# 4. data_temp_new — результаты измерения температуры;
# 5. data_wire_new — данные о проволочных материалах (объём);
# 
# Две таблицы 'data_bulk_time_new — данные о подаче сыпучих материалов (время)' и 'data_wire_time_new — данные о проволочных материалах (время)' на следующих этапах участвовать не будут, т.к. были откинуты с точки зрения неинформативности для реализации задачи.

# ### Исследовательский анализ и предобработка данных таблицы 'data_arc_new'

# In[186]:


# снова посмотрим первые 5 строк таблицы
data_arc_new.head()


# In[187]:


# для начала изменим названия столбцов, приведя их к общепринятому стилю
data_arc_new = data_arc_new.rename(columns={
    'Начало нагрева дугой' : 'beginning_of_arc',
    'Конец нагрева дугой' : 'end_of_arc',
    'Активная мощность' : 'active_power',
    'Реактивная мощность' : 'reactive_power'
})


# In[188]:


# посмотрим названия столбцов после изменения
data_arc_new.head()


# In[189]:


# посмотрим информацию о таблице
data_arc_new.info()


# In[190]:


# столбцы 'beginning_of_arc' и 'end_of_arc' имеют неправильный тип данных, необходимо заменить на 'datetime'
data_arc_new['beginning_of_arc'] = pd.to_datetime(data_arc_new['beginning_of_arc'])
data_arc_new['end_of_arc'] = pd.to_datetime(data_arc_new['end_of_arc'])


# In[191]:


# посмотрим общую информацию о таблице после изменений
data_arc_new.info()


# In[192]:


# посмотрим количество пропусков в данных
data_arc_new.isna().sum()


# **Примечание:** Пропуски в данных полностью отсутствуют.

# In[193]:


# проверим датафрейм на наличие явных дубликатов
data_arc_new.duplicated().sum()


# **Примечание:** Явные дубликаты в данных отсутствуют.

# In[194]:


# проведем статистический анализ количественных признаков
print('Описательная статистика для количественных признаков:')
data_arc_new.describe(include=[np.number])


# In[195]:


# напишем собственную функцию для визуализации количественных признаков
def numeric(data, column, title):
    # устанавливаем параметры графика
    sns.set()
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 3))
    
    # построение гистограммы для количественных признаков 
    sns.histplot(data, x=column, bins=20, kde=True, ax=ax1, color='lightpink')
    ax1.set_title(f'Гистограмма для {column}')
    ax1.set_xlabel(f'Значения столбца {column}')
    ax1.set_ylabel('Частота')
    
    # построение графика "Ящик с усами"
    sns.boxplot(data=data, x=column, ax=ax2, color='lightblue')
    ax2.set_title(f'Ящик с усами для {column}')
    ax2.set_xlabel(column)
    
    # окончательная настройка графика
    plt.suptitle(title)
    plt.tight_layout()
    plt.show()


# In[196]:


# визуализация признака 'active_power'
numeric(data_arc_new, 'active_power', 'Значение активной мощности')


# In[197]:


# визуализация признака 'reactive_power'
numeric(data_arc_new, 'reactive_power', 'Значение реактивной мощности')


# **Примечание:**
# 1. По результатам визализации признака 'active_power' заметно небольшое смещение графика влево.
# 2. По результатам визуализации признака 'reactive_power' на графике "Ящик с усами" виден один большой аномально отрицательный выброс. Данный выброс стоит обработать.

# In[198]:


# посмотрим на значения строки с аномальным отрицательным значением признака 'reactive_power'
data_arc_new[data_arc_new['reactive_power'] < 0]


# In[199]:


# данный выброс один, его стоит обработать, поэтому удалим строку с аномальным значением по значения столбца 'key'
data_arc_new = data_arc_new[data_arc_new['key'] != 2116]


# In[200]:


# посмотрим общую информацию о таблице после удаления
data_arc_new.info()


# **Примечание:** Удаление произведено корректно, без изменения остальных данных.

# In[201]:


# для того чтобы определить общие затраты электроэнергии на нагрев стали рассчитаем полную мощность
# полная можность = кв. кор. (активная мощность ^2 + реактивная мозность ^2)
data_arc_new['power'] = ((data_arc_new['active_power']) ** 2 + (data_arc_new['reactive_power']) ** 2) ** 0.5

# сразу посмотрим первые 5 строк таблицы с новым признаком
data_arc_new.head()


# In[202]:


# визуализируем признаки начала и окончания времени нагрева
plt.figure(figsize=(16, 8))  

ax = data_arc_new['beginning_of_arc'].plot(label='begin', linewidth=3.0, color='green', alpha=0.8)
ax = data_arc_new['end_of_arc'].plot(label='end', linewidth=2.0, color='orange', alpha=0.8)

ax.set_xlabel('Номер партии', fontsize=12)
ax.set_ylabel('Дата', fontsize=12)
ax.set_title('Время начала и окончания нагрева по партиям', fontsize=14)
ax.legend(fontsize=11)
ax.grid(True, alpha=0.3)

plt.xticks(rotation=45)
plt.tight_layout() 
plt.show()


# **Примечание:** Время начала и окончания нагрева не сильно важно для исследования, но общее затраченное время может понадобиться для итогового расчета температуры, поэтому рассчитаем его на всякий случай. Если посмотреть на значения таблицы, то в целом время нагрева варьируется от 2 до 6 минут и определенного количества секунд, поэтому стоит рассчитать время в секундах, чтобы учесть всю продолжительность.

# In[203]:


# рассчитаем интервал между началом и окончанием нагрева в секундах
data_arc_new['time_interval'] = data_arc_new['end_of_arc'] - data_arc_new['beginning_of_arc']
data_arc_new['time_interval'] = data_arc_new['time_interval'].dt.total_seconds()


# In[204]:


# посмотрим первые 5 строк таблицы с новым признаком
data_arc_new.head()


# **Примечание:** После преобразования для нашего исследования можно оставить только признаки 'power' (полная мощность, которая ключает в себя, как активную, так и реактивную мощности) и 'time_imterval' (промежуток времени между началом и окончанием нагрева), остальные признаки не нужны, т.к. они включены в предыдущие два. Также, как было замечено при первичном просмотре данных, некоторые партии нагреваются по несколько раз, чтобы собрать общую инфрмацию, объединим их по уникальным значениям столбца 'key'.

# In[205]:


# проведем объединение данных в новой таблице
key_arc_new = data_arc_new.groupby('key')[['power', 'time_interval']].sum().reset_index()

# посмотрим первые 5 строк новой таблицы
key_arc_new.head()


# In[206]:


# посмотрим общую информацию о новой таблице
key_arc_new.info()


# **Примечание:** Пропуски в новой таблице отсутствуют.

# In[207]:


# проведем статистический анализ количественных признаков для новой таблицы
print('Описательная статистика для количественных признаков:')
key_arc_new.describe(include=[np.number])


# In[208]:


# визуализация признака 'power'
numeric(key_arc_new, 'power', 'Значение полной мощности')


# In[209]:


# визуализация признака 'time_interval'
numeric(key_arc_new, 'time_interval', 'Значение временного интервала между началом и окончанием нагрева')


# **Примечание:** Распределение обоих признаков похоже на нормальное или близко к нему. Выбросы есть для обоих признаков, но они не критичны для исследования (все критичные выбросы были обработаны ранее).

# ### Исследовательский анализ и предобработка данных таблицы 'data_bulk_new'

# In[210]:


# снова посмотрим первые 5 строк таблицы
data_bulk_new.head()


# In[211]:


# посмотрим последние 5 строк таблицы
data_bulk_new.tail()


# In[212]:


# для начала изменим названия столбцов, приведя их к общепринятому стилю
data_bulk_new = data_bulk_new.rename(columns={
    'Bulk 1' : 'bulk_1',
    'Bulk 2' : 'bulk_2',
    'Bulk 3' : 'bulk_3',
    'Bulk 4' : 'bulk_4',
    'Bulk 5' : 'bulk_5',
    'Bulk 6' : 'bulk_6',
    'Bulk 7' : 'bulk_7',
    'Bulk 8' : 'bulk_8',
    'Bulk 9' : 'bulk_9',
    'Bulk 10' : 'bulk_10',
    'Bulk 11' : 'bulk_11',
    'Bulk 12' : 'bulk_12',
    'Bulk 13' : 'bulk_13',
    'Bulk 14' : 'bulk_14',
    'Bulk 15' : 'bulk_15'
})


# In[213]:


# посмотрим названия столбцов после изменения
data_bulk_new.head()


# In[214]:


# посмотрим информацию о таблице
data_bulk_new.info()


# **Примечание:** Названия столбцов приведены к общепринятому стилю, типы данных казаны корректно.

# In[215]:


# посмотрим количество пропусков в данных
data_bulk_new.isna().sum()


# **Примечание:** Видно, что присутствует достаточно много пропущенных значений, однако, это те пропуски, когда во время производства материал не подавался, соответственно, это естественный процесс производства, а значит, что все присутствующие пропуски можно заметить на ноль.

# In[216]:


# заполним пропущенные значения
data_bulk_new = data_bulk_new.fillna(0)

# посмотрим количество пропусков после заполнения
data_bulk_new.isna().sum()


# In[217]:


# проверим датафрейм на наличие явных дубликатов
data_bulk_new.duplicated().sum()


# **Примечание:** Явные дубликаты в данных отсутсвуют.

# In[218]:


# проведем статистический анализ количественных признаков
print('Описательная статистика для количественных признаков:')
data_bulk_new.describe(include=[np.number])


# In[219]:


# визуализация признака 'bulk_1'
numeric(data_bulk_new, 'bulk_1', 'Объем подаваемого материала №1')


# In[220]:


# визуализация признака 'bulk_2'
numeric(data_bulk_new, 'bulk_2', 'Объем подаваемого материала №2')


# In[221]:


# визуализация признака 'bulk_3'
numeric(data_bulk_new, 'bulk_3', 'Объем подаваемого материала №3')


# In[222]:


# визуализация признака 'bulk_4'
numeric(data_bulk_new, 'bulk_4', 'Объем подаваемого материала №4')


# In[223]:


# визуализация признака 'bulk_5'
numeric(data_bulk_new, 'bulk_5', 'Объем подаваемого материала №5')


# In[224]:


# визуализация признака 'bulk_6'
numeric(data_bulk_new, 'bulk_6', 'Объем подаваемого материала №6')


# In[225]:


# визуализация признака 'bulk_7'
numeric(data_bulk_new, 'bulk_7', 'Объем подаваемого материала №7')


# In[226]:


# визуализация признака 'bulk_8'
numeric(data_bulk_new, 'bulk_8', 'Объем подаваемого материала №8')


# In[227]:


# визуализация признака 'bulk_9'
numeric(data_bulk_new, 'bulk_9', 'Объем подаваемого материала №9')


# In[228]:


# визуализация признака 'bulk_10'
numeric(data_bulk_new, 'bulk_10', 'Объем подаваемого материала №10')


# In[229]:


# визуализация признака 'bulk_11'
numeric(data_bulk_new, 'bulk_11', 'Объем подаваемого материала №11')


# In[230]:


# визуализация признака 'bulk_12'
numeric(data_bulk_new, 'bulk_12', 'Объем подаваемого материала №12')


# In[231]:


# визуализация признака 'bulk_13'
numeric(data_bulk_new, 'bulk_13', 'Объем подаваемого материала №13')


# In[232]:


# визуализация признака 'bulk_14'
numeric(data_bulk_new, 'bulk_14', 'Объем подаваемого материала №14')


# In[233]:


# визуализация признака 'bulk_15'
numeric(data_bulk_new, 'bulk_15', 'Объем подаваемого материала №15')


# **Примечание:** Почти для каждого из разов, когда подавался тот или иной объем производства, присутствуют выбросы, однако эти выбросы связаны с процессом производства, поэтому они останутся без изменений.

# In[234]:


# стоит отметить, что в данной таблице партии производства идут по порядку и каждая из них встречается один раз
# поэтому для каждой итерации можно посчитать сумму тех, где ничего не добавляется для уменьшения общего количества признаков
data_bulk_new['all_bulk_zero'] = data_bulk_new[['bulk_1', 'bulk_2', 'bulk_5', 
                                          'bulk_7', 'bulk_8', 'bulk_9', 'bulk_10',
                                          'bulk_11', 'bulk_13']].sum(axis=1)

# посмотрим первые 5 строк новой таблицы
data_bulk_new.head()


# ### Исследовательский анализ и предобработка данных таблицы 'data_gas_new'

# In[235]:


# снова посмотрим первые 5 строк таблицы
data_gas_new.head()


# In[236]:


# для начала изменим названия столбцов, приведя их к общепринятому стилю
data_gas_new = data_gas_new.rename(columns={
    'Газ 1' : 'gas_1'
})


# In[237]:


# посмотрим названия столбцов после изменения
data_gas_new.head()


# In[238]:


# посмотрим информацию о таблице
data_gas_new.info()


# In[239]:


# посмотрим количество пропусков в данных
data_gas_new.isna().sum()


# **Примечание:** Пропуски в данных отсутствуют.

# In[240]:


# проверим датафрейм на наличие явных дубликатов
data_gas_new.duplicated().sum()


# **Примечание:** Явные дубликаты в данных отсутствуют.

# In[241]:


# проведем статистический анализ количественных признаков
print('Описательная статистика для количественных признаков:')
data_gas_new.describe(include=[np.number])


# In[242]:


# визуализация признака 'gas_1'
numeric(data_gas_new, 'gas_1', 'Объем подаваемого газа')


# **Примечание:** По результатм визуализации стало видно, что присутствует достаточно много выбросов, однако они удалены не будут, т.к. являются нормальными при процессе производства.

# ### Исследовательский анализ и предобработка данных таблицы 'data_temp_new'

# In[243]:


# снова посмотрим первые 5 строк таблицы
data_temp_new.head()


# In[244]:


# для начала изменим названия столбцов, приведя их к общепринятому стилю
data_temp_new = data_temp_new.rename(columns={
    'Время замера' : 'measurement_time',
    'Температура' : 'temperature'
})


# In[245]:


# посмотрим названия столбцов после изменения
data_temp_new.head()


# In[246]:


# посмотрим информацию о таблице
data_temp_new.info()


# In[247]:


# столбец 'measurement_time' имеет неправильный тип данных, необходимо заменить на 'datetime'
data_temp_new['measurement_time'] = pd.to_datetime(data_temp_new['measurement_time'])


# In[248]:


# посмотрим общую информацию о таблице после изменений
data_temp_new.info()


# In[249]:


# посмотрим количество пропусков в данных
data_temp_new.isna().sum()


# **Примечание:** Присутствует достаточно большое количество пропусков в столбце 'temperature', их необходимо обработать.

# In[250]:


# проверим датафрейм на наличие явных дубликатов
data_temp_new.duplicated().sum()


# **Примечание:** Явные дубликаты отсутствуют.

# Также по условиям реализации задачи для заказчика конечная температура будет являться целевым признаком, который стоит предсказать, соответственно, в процессе работы стоит использовать начальную температуру, чтобы не произошла утечка данных. 

# In[251]:


# разделим температуру на начальную и конечную, используя 'measurement_time'
# найдем все значения начальной температуры
data_temp_begin = data_temp_new.loc[data_temp_new.groupby(['key'])['measurement_time'].idxmin()]
# найдем все значения конечной температуры
data_temp_end = data_temp_new.loc[data_temp_new.groupby(['key'])['measurement_time'].idxmax()]


# In[252]:


# объединим две разделенные таблицы в одну по столбцу 'key'
data_temp = pd.merge(data_temp_begin, data_temp_end, on='key')

# посмотрим первые 5 строк получившейся таблицы
data_temp.head()


# **Примечание:** Таблицы объединились корректно, однако, названия столбцов не очень ясны, поэтому их стоит переименовать.

# In[253]:


# переименуем столбцы в получившейся таблице
data_temp = data_temp.rename(columns={
    'measurement_time_x' : 'measurement_time_begin',
    'temperature_x' : 'temperature_begin',
    'measurement_time_y' : 'measurement_time_end',
    'temperature_y' : 'temperature_end'
})


# In[254]:


# посмотрим таблицу после переименования столбцов
data_temp.head()


# In[255]:


# посмотрим общую информацию о таблице
data_temp.describe()


# **Примечание:** По полученным результатам видно, что в столбце 'temperature_begin' присутствует аномалия, т.к. минимальная температура в ней равна 1191.00, но стоит отметить, что по результатам поиска, было найдено, что минимальная температура нагрева стали равна 1400.00. Эту аномалию стоит обработать.

# In[256]:


# посмотрим сколько в таблице записей с начальной температурой меньше, чем 1400.00
data_temp[data_temp['temperature_begin'] < 1400]


# In[257]:


# записей с аномальной начальной температурой оказалось всего 5, их стоит удалить
data_temp = data_temp[data_temp['key'] != 867]
data_temp = data_temp[data_temp['key'] != 1214]
data_temp = data_temp[data_temp['key'] != 1619]
data_temp = data_temp[data_temp['key'] != 2052]
data_temp = data_temp[data_temp['key'] != 2561]


# In[258]:


# посмотрим на кол-во строк с начальной температурой меньше 1400.00 после удаления
data_temp[data_temp['temperature_begin'] < 1400]


# **Примечание:** Аномально маленькие значения начальной температуры успешно обработаны.

# In[259]:


# посмотрим количество пропусков в данных на нынешний момент
data_temp.isna().sum()


# **Примечание:** В таблице присутствуют пропуски только в одном столбце, а именно 'temperature_end', который является целевым, соответственно востанавливать пропуски в этом столбце нецелесообразно, т.к. это действие может исказить предсказание. В связи с этим пропуски в этом столбце будут просто удалены.

# In[260]:


# удалим пропуски в столбце 'temperature_end'
data_temp = data_temp.dropna()

# посмотрим кол-во пропусков в таблице после удаления
data_temp.isna().sum()


# **Примечание:** Все аномалии и пропуски в данных успешно обработаны.

# In[261]:


# проведем статистический анализ количественных признаков
print('Описательная статистика для количественных признаков:')
data_temp.describe(include=[np.number])


# In[262]:


# визуализация признака 'temperature_begin'
numeric(data_temp, 'temperature_begin', 'Значение начальной температуры')


# In[263]:


# визуализация признака 'temperature_end'
numeric(data_temp, 'temperature_end', 'Значение конечной температуры')


# **Примечание:** По графикам тоже видно, что все критичные значения обработаны, жа, присутствуют и другие выбросы, но они не влияют на процесс исследования.

# In[264]:


# визуализируем признаки начала и окончания времени замера
plt.figure(figsize=(16, 8))  

ax = data_temp['measurement_time_begin'].plot(label='begin', linewidth=3.0, color='green', alpha=0.8)
ax = data_temp['measurement_time_end'].plot(label='end', linewidth=2.0, color='orange', alpha=0.8)

ax.set_xlabel('Номер партии', fontsize=12)
ax.set_ylabel('Дата', fontsize=12)
ax.set_title('Время начала и окончания замера по партиям', fontsize=14)
ax.legend(fontsize=11)
ax.grid(True, alpha=0.3)

plt.xticks(rotation=45)
plt.tight_layout() 
plt.show()


# **Примечание:** Время начала и окончания замера температуры не сильно важно для исследования (тем более, что ранее сама температура была разделена на начальную и конечную), но общее затраченное время может понадобиться для итогового предсказания температуры, поэтому рассчитаем его на всякий случай. Если посмотреть на значения таблицы, то в целом время замера температуры варьируется в пределах минуты, но некоторое и за считанные секунды, поэтому стоит рассчитать время в секундах, чтобы учесть всю продолжительность.

# In[265]:


# рассчитаем интервал между началом и окончанием замера температуры в секундах
data_temp['time'] = data_temp['measurement_time_end'] - data_temp['measurement_time_begin']
data_temp['time'] = data_temp['time'].dt.total_seconds()


# In[266]:


# посмотрим первые 5 строк таблицы с новым признаком
data_temp.head()


# **Примечание:** После преобразования для нашего исследования можно оставить только признаки 'temperature_begin' (начальная температура), 'temperature_end' (конечная температура) и 'time' (промежуток времени между началом и окончанием замера температуры), остальные признаки не нужны, т.к. они включены в предыдущие два.

# ### Исследовательский анализ и предобработка данных таблицы 'data_wire_new'

# In[267]:


# снова посмотрим первые 5 строк таблицы
data_wire_new.head()


# In[268]:


# снова посмотрим первые 5 строк таблицы
data_wire_new.head()


# In[269]:


# для начала изменим названия столбцов, приведя их к общепринятому стилю
data_wire_new = data_wire_new.rename(columns={
    'Wire 1' : 'wire_1',
    'Wire 2' : 'wire_2',
    'Wire 3' : 'wire_3',
    'Wire 4' : 'wire_4',
    'Wire 5' : 'wire_5',
    'Wire 6' : 'wire_6',
    'Wire 7' : 'wire_7',
    'Wire 8' : 'wire_8',
    'Wire 9' : 'wire_9'
})


# In[270]:


# посмотрим названия столбцов после изменения
data_wire_new.head()


# In[271]:


# посмотрим информацию о таблице
data_wire_new.info()


# **Примечание:** Названия столбцов приведены к общепринятому стилю, типы данных указаны корректно.

# In[272]:


# посмотрим количество пропусков в данных
data_wire_new.isna().sum()


# **Примечание:** Видно, что присутствует достаточно много пропущенных значений, однако, это те пропуски, когда во время производства проволочный материал не подавался, соответственно, это естественный процесс производства, а значит, что все присутствующие пропуски можно заметить на ноль.

# In[273]:


# заполним пропущенные значения
data_wire_new = data_wire_new.fillna(0)

# посмотрим количество пропусков после заполнения
data_wire_new.isna().sum()


# In[274]:


# проверим датафрейм на наличие явных дубликатов
data_wire_new.duplicated().sum()


# **Примечание:** Явные дубликаты в данных отсутсвуют.

# In[275]:


# проведем статистический анализ количественных признаков
print('Описательная статистика для количественных признаков:')
data_wire_new.describe(include=[np.number])


# In[276]:


# визуализация признака 'wire_1'
numeric(data_wire_new, 'wire_1', 'Объем подаваемого проволочного материала №1')


# In[277]:


# визуализация признака 'wire_2'
numeric(data_wire_new, 'wire_2', 'Объем подаваемого проволочного материала №2')


# In[278]:


# визуализация признака 'wire_3'
numeric(data_wire_new, 'wire_3', 'Объем подаваемого проволочного материала №3')


# In[279]:


# визуализация признака 'wire_4'
numeric(data_wire_new, 'wire_4', 'Объем подаваемого проволочного материала №4')


# In[280]:


# визуализация признака 'wire_5'
numeric(data_wire_new, 'wire_5', 'Объем подаваемого проволочного материала №5')


# In[281]:


# визуализация признака 'wire_6'
numeric(data_wire_new, 'wire_6', 'Объем подаваемого проволочного материала №6')


# In[282]:


# визуализация признака 'wire_7'
numeric(data_wire_new, 'wire_7', 'Объем подаваемого проволочного материала №7')


# In[283]:


# визуализация признака 'wire_8'
numeric(data_wire_new, 'wire_8', 'Объем подаваемого проволочного материала №8')


# In[284]:


# визуализация признака 'wire_9'
numeric(data_wire_new, 'wire_9', 'Объем подаваемого проволочного материала №9')


# **Примечание:** Почти для каждого из разов, когда подавался тот или иной объем производства, присутствуют выбросы, однако эти выбросы связаны с процессом производства, поэтому они останутся без изменений.

# In[285]:


# стоит отметить, что в данной таблице партии производства идут по порядку и каждая из них встречается один раз
# поэтому для каждой итерации можно посчитать сумму тех, где ничего не добавляется для уменьшения общего количества признаков
data_wire_new['all_wire_zero'] = data_wire_new[['wire_3', 'wire_4', 'wire_5', 
                                          'wire_6', 'wire_7', 'wire_8', 'wire_9']].sum(axis=1)

# посмотрим первые 5 строк новой таблицы
data_wire_new.head()


# **Обобщающий вывод этапа "Исследовательский анализ и предобработка данных":**
# 1. Названия во всех таблицах приведены к общепринятому "змеиному" стилю.
# 2. Во всех таблицах отсутствуют явные дубликаты.
# 3. Пропуски в таблицах 'data_bulk_new' и 'data_wire_new' заполнены нулями.
# 4. В таблицах 'data_arc_new' и 'data_temp_new' обработаны аномалии в столбцах 'reactive_power' (реактивная мощность) и 'temperature_begin' (начальная температура) соответственно.
# 5. Рассчитаны новые признаки: 'power' (полная мощность, включающая в себя активную и реактивную мощности), 'time_interval' (время в секундах между началом и окончанием нагрева), 'all_bulk_zero' (столбец со значениями всех нулевых итераций по подаче материалов), 'temperature_begin' и 'temperature_end' (начальная и конечная температуры соответственно), 'time' (время в секундах между началом и окончанием нагрева температуры), 'all_wire_zero' (столбец со значениями всех нулевых итераций по подаче проволочных материалов).

# ## Объединение данных

# In[286]:


# для будущего построения моделей объединим все получившиеся таблицы из п.2 и удалим оттуда неинформативные столбцы
data = pd.merge(key_arc_new, data_bulk_new, on='key')
data = data.merge(data_gas_new, on='key')
data = data.merge(data_temp, on='key')
data = data.merge(data_wire_new, on='key')


# In[287]:


# посмотрим первые 5 строк получившейся таблицы
data.head()


# In[288]:


# т.к. не все столбцы нужны для исследования, посмотрим список и удалим ненужные
data.columns


# In[289]:


data = data.drop(['bulk_1', 'bulk_2',
                'bulk_5', 'bulk_7',
                'bulk_8', 'bulk_9',
                'bulk_10', 'bulk_11',
                'bulk_13', 'measurement_time_begin',
                'measurement_time_end', 'wire_3',
                'wire_4','wire_5', 
                'wire_6', 'wire_7', 
                'wire_8','wire_9'], axis=1)


# In[290]:


# посмотрим получившуюся таблицу
data.head()


# In[291]:


# в целом признак 'key' тоже является неинформативным для исследования, поэтому удалим его
data = data.drop(['key'], axis=1)


# In[292]:


# посмотрим общую информацию о таблице
data.info()


# In[293]:


# посмотрим полученную таблицу на наличие пропусков
data.isna().sum()


# In[294]:


# посмотрим полученную таблицу на наличие явных дубликатов
data.duplicated().sum()


# **Обобщающий вывод этапа "Объединение таблиц":**
# 1. На данном этапе все 5 таблиц после предобработки были объединены в одну общую таблицу.
# 2. Также были удалены столбцы, которые не являются информативными для исследования, а именно вся необходимая инфрмация из них содержится в других столбцах.
# 3. Пропуски и явные дубликаты в полученной таблице отсутствуют.

# ## Исследовательский анализ и предобработка данных объединенного датафрейма

# In[295]:


# снова посмотрим первые 5 строк получившегося датафрейма
data.head()


# In[296]:


# в нашем датафрейме присутствуют только количественные признаки, посмотрим их описательную статистику
print('Описательная статистика для количественных признаков:')
data.describe(include=[np.number])


# In[297]:


# визуализация признака 'power'
numeric(data, 'power', 'Значение полной мощности')


# In[298]:


# визуализация признака 'time_interval'
numeric(data, 'time_interval', 'Значение времени (в секундах) между началом и окончанием нагрева')


# In[299]:


# визуализация признака 'bulk_3'
numeric(data, 'bulk_3', 'Объем подаваемого материала №3')


# In[300]:


# визуализация признака 'bulk_4'
numeric(data, 'bulk_4', 'Объем подаваемого материала №4')


# In[301]:


# визуализация признака 'bulk_6'
numeric(data, 'bulk_6', 'Объем подаваемого материала №6')


# In[302]:


# визуализация признака 'bulk_12'
numeric(data, 'bulk_12', 'Объем подаваемого материала №12')


# In[303]:


# визуализация признака 'bulk_14'
numeric(data, 'bulk_14', 'Объем подаваемого материала №14')


# In[304]:


# визуализация признака 'bulk_15'
numeric(data, 'bulk_15', 'Объем подаваемого материала №15')


# In[305]:


# визуализация признака 'all_bulk_zero'
numeric(data, 'all_bulk_zero', 'Объем подаваемого материала для всех нулевых итераций')


# In[306]:


# визуализация признака 'gas_1'
numeric(data, 'gas_1', 'Объем подаваемого газа')


# In[307]:


# визуализация признака 'temperature_begin'
numeric(data, 'temperature_begin', 'Значение начальной температуры')


# In[308]:


# визуализация признака 'temperature_end'
numeric(data, 'temperature_end', 'Значение конечной температуры')


# In[309]:


# визуализация признака 'time'
numeric(data, 'time', 'Время (в секундах) между началом и окончанием нагрева температуры')


# In[310]:


# визуализация признака 'wire_1'
numeric(data, 'wire_1', 'Объем подаваемого проволочного материала №1')


# In[311]:


# визуализация признака 'wire_2'
numeric(data, 'wire_2', 'Объем подаваемого проволочного материала №2')


# In[312]:


# визуализация признака 'all_wire_zero'
numeric(data, 'all_wire_zero', 'Объем подаваемого проволочного материала для всех нулевых итераций')


# **Примечание:** Все признаки нового датафрейма корректно обработаны, присутствуют выбросы, но они не относятся к аномалиям, т.к. являются частью производственного процесса.

# ### Проведение корреляционного анализа признаков в объединенном датафрейме

# In[313]:


# в нашем датафрейме присутствуют только количественное переменные, поэтому не будем объединять их в отдельную переменную
# рассчитаем коэффиценты корреляции для количественных признаков
data.corr()


# In[314]:


# нарисуем тепловую карту для визуализации результатов полученных коэффициентов корреляции
plt.figure(figsize=(16,8))
sns.heatmap(
    data.corr(),        
    cmap='RdBu_r',
    annot=True, 
    vmin=-1, vmax=1)
plt.title("Тепловая карта корреляции")
plt.show();


# **Примечание:** 
# 
# **Целевой признак:** 'temperature_end' (значение конечной температуры).
# 1. Зависимость целевого признака с отстальными достаточно низкая, значения коэффициента корреляции колеблется возле нуля.
# 2. Связь между признаками 'power' (полная мощность) и 'time_interval' (значение времени (в секундах) между началом и окончанием нагрева) линейная и сильная, это подтверждает полученные коэффициент корреляции, равный 0.72.
# 3. Мультиколлинеарность между входными признаками не наблюдается.

# **Обобщающий вывод этапа "Исследовательский анализ и предобработка данных объединенного датафрейма":**
# 1. Все признаки нового датафрейма корректно обработаны, присутствуют выбросы, но они не относятся к аномалиям, т.к. являются частью производственного процесса.
# 2. Зависимость целевого признака ('temperature_end' (значение конечной температуры)) с отстальными достаточно низкая, значения коэффициента корреляции колеблется возле нуля.
# 3. Связь между признаками 'power' (полная мощность) и 'time_interval' (значение времени (в секундах) между началом и окончанием нагрева) линейная и сильная, это подтверждает полученные коэффициент корреляции, равный 0.72.
# 4. Мультиколлинеарность между входными признаками не наблюдается.

# ## Подготовка данных

# In[315]:


# разделим сформированный датасет на целевой признак и остальные
X = data.drop('temperature_end', axis=1)
y = data['temperature_end']


# In[316]:


# выделяем тренировочную и тестовую выборки
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=RANDOM_STATE, shuffle=True
)


# In[318]:


# проверяем корректность разбиения на выборки
print('Размер тренировочной выборки - {:.0%}'.format(X_train.shape[0] / X.shape[0]))
print('Размер тестовой выборки - {:.0%}'.format(X_test.shape[0] / X.shape[0]))


# In[319]:


print(f"X_train размерность: {X_train.shape}")
print(f"X_test размерность: {X_test.shape}")


# **Обобщающий вывод этапа "Подготовка данных":** 
# 1. Данные разбиты на тренировочную и тестовую выборки, 75% и 25% соответственно.
# 2. Полученные размерности выборок соответствуют действительности.

# ## Обучение моделей машинного обучения

# На данном этапе модели будут обучаться с помощью кросс-валидации, тестовая выборка будет использоваться только один раз при проверке качества лучшей модели.
# 
# Будут использоваться следующие модели:
# 1. LinearRegression (для этой модели будет реализовано масштабирование данных);
# 2. DecisionTreeRegressor (для этой модели будет реализован подбор гиперпараметров);
# 3. CatBoostRegressor (для этой модели будут фиксированные параметры);
# 4. LightGBM (для этой модели будут фиксированные параметры).

# In[320]:


# напишем собственную функцию для расчета времени обучения, предсказания и метрики качества МАЕ (с использованием кросс-валидации)
def crossval_evaluate_model(model, X_train, y_train, cv=5):
    # инициализируем метод кросс-валидации для временных рядов
    kf = KFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE)

    mae, train_time, pred_time = [], [], []

    # разделение данных с учетом кросс-валидации
    for train_idx, valid_idx in kf.split(X_train):
        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]
        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]

        # обучение модели и замер времени для этого
        start_train = time.time()
        model.fit(X_tr, y_tr)
        train_time.append(time.time() - start_train)

        # предсказание модели и замер времени для этого
        start_pred = time.time()
        y_pred = model.predict(X_val)
        pred_time.append(time.time() - start_pred)

        # расчет метрики
        mae.append(mean_absolute_error(y_val, y_pred))

    return np.mean(mae), np.mean(train_time), np.mean(pred_time)


# In[321]:


# создаем модели 
models = {
    "LinearRegression": Pipeline([
        ("scaler", StandardScaler()),
        ("model", LinearRegression())
    ]),
    "DecisionTreeRegressor": DecisionTreeRegressor(random_state=RANDOM_STATE),
    "CatBoostRegressor": CatBoostRegressor(random_state=RANDOM_STATE, verbose=100),
    "LightGBM": LGBMRegressor(random_state=RANDOM_STATE, n_jobs=-1)
}


# In[322]:


results = []

# запись всех результатов в окончательную таблицу
for name, model in models.items():
    mae_cv, train_time, pred_time = crossval_evaluate_model(model, X_train, y_train, cv=5)
    results.append({
        "Модель": name,
        "MAE (на CV)": mae_cv,
        "Время обучения (с) (на CV)": train_time,
        "Время предсказания (с) (на CV)": pred_time
    })


# In[323]:


# подберем наилучшие гиперпараметры для модели DecisionTreeRegressor
# составим список параметров
param_grid = {
    "max_depth": [3, 5, 7, 10, None],
    "min_samples_split": [2, 5, 10, 20],
    "min_samples_leaf": [1, 2, 4, 10]
}


# In[324]:


# инициализируем модель
dtr_model = DecisionTreeRegressor(random_state=RANDOM_STATE)


# In[325]:


# подбор гиперпараметров
search = RandomizedSearchCV(
    dtr_model,
    param_distributions=param_grid,
    n_iter=20,
    scoring="neg_mean_absolute_error",
    cv=5,
    random_state=RANDOM_STATE,
    n_jobs=-1
)

search.fit(X_train, y_train)


# In[326]:


# оценим найденную модель через собственную функцию
mae_cv, train_time, pred_time = crossval_evaluate_model(search.best_estimator_, X_train, y_train, cv=5)
results.append({
    "Модель": "DecisionTreeRegressor (с гиперпараметрами)",
    "MAE (на CV)": mae_cv,
    "Время обучения (с) (на CV)": train_time,
    "Время предсказания (с) (на CV)": pred_time
})


# In[327]:


# выводим результаты в виде таблицы с сортировкой
df_results = pd.DataFrame(results).sort_values(by="MAE (на CV)")
df_results


# **Обобщающий вывод этапа "Обучение моделей машинного обучения":**
# 1. По метрике оценки качества МАЕ, которая по условию задачи должна быть меньше 6.8, лучше всего себя показала модель: CatBoostRegressor.
# 2. Самой быстрой по сравнению с другими и подходящей по критериям для метрики оценки качества оказалась модель: LinearRegression. Однако результаты ее метрики качества оказали ниже, чем у CatBoostRegressor.
# 3. Модель DecisionTreeRegressor как с гиперпараметрами, так и без них, показала наихудший результат, не подходящий под критерий от заказчика, по метрике оценки качества МАЕ. Однако стоит отметить, что модель DecisionTreeRegressor (с гиперпараметрами) оказалась самой быстрой по времени обучения и предсказания среди всех рассматриваемых моделей.

# ## Выбор лучшей модели и проверка ее качества на тестовой выборке

# In[328]:


# повторный вывод результата
df_results


# **Примечание:** Лучшей моделью по метрике оценки качества МАЕ оказалась CatBoostRegressor (МАЕ = 5.89 на кросс-валидации), она удовлетворяет условию заказчика, что МАЕ должна быть не выше 6.8. Для проверки качества на тестовой выборке будем брать именно ее. Однако стоит отметить, что если бы еще одним условием заказчика была скорость работы модели, а именно время обучения и предсказания, то гланым претендентом была бы модель LinearRegression, которая несильно уступает по метрике качества МАЕ, но операжает модель CatBoostRegressor по скорости.

# In[329]:


# выбираем лучшую модель
best_model = CatBoostRegressor(random_state=RANDOM_STATE, verbose=100)
best_model.fit(X_train, y_train)


# In[330]:


get_ipython().run_cell_magic('time', '', 'start_test_pred = time.time()\ny_test_pred = best_model.predict(X_test)\ntest_pred_time = time.time() - start_test_pred\n')


# In[331]:


# расчет МАЕ на тестовой выборке
mae_test = mean_absolute_error(y_test, y_test_pred)

# вывод итоговых результатов
print(f"МАЕ на тестовой выборке: {mae_test:.2f}")
print(f"Время предсказания: {test_pred_time:.4f} секунд")


# In[332]:


# проведем сравнение со значением метрики МАЕ константной модели
# обучаем DummyRegressor 
dummy = DummyRegressor(strategy="mean")
dummy.fit(X_train, y_train)

# проводим предсказание на тестовой выборке
y_pred_dummy = dummy.predict(X_test)

# считаем метрику-качества MAE на константной модели
mae_dummy = mean_absolute_error(y_test, y_pred_dummy)

print(f"MAE DummyRegressor (константной модели): {mae_dummy:.4f}")


# **Примечание:** Полученная метрика оценки качества МАЕ на модели CatBoostRegressor(random_state=RANDOM_STATE, verbose=100) составила 5.98, что является меньше, чем значение МАЕ, равное 7.78, на константной модели (DummyRegressor), а это значит, что модель реально обучается и является полезной.

# In[333]:


# получаем SHAP-значения 
explainer = shap.TreeExplainer(best_model)
shap_values = explainer.shap_values(X_test)


# In[334]:


# строим графики важности признаков
shap.summary_plot(shap_values, X_test, plot_type="bar")
shap.summary_plot(shap_values, X_test) 


# **Примечание:** Наибольшим весом для модели обладают признаки: 'time_interval' (значение времени (в секундах) между началом и окончанием нагрева), 'temperature_begin' (начальная температура), 'time' (время (в секундах) между началом и окончанием нагрева температуры). Сильную связь признаков 'time_interval' и 'temperature_begin' с целевым признаком ('temperature_end') можно объяснить тем, что они являются частью единого процесса нагрева стали.

# **Обобщающий вывод этапа "Выбор лучшей модели и проверка ее качества на тестовой выборке":**
# 1. Лучшей моделью по метрике оценки качества МАЕ оказалась CatBoostRegressor (МАЕ = 5.89 на кросс-валидации), она удовлетворяет условию заказчика, что МАЕ должна быть не выше 6.8. Значение метрики качества МАЕ модели на **тестовой выборке** составило 5.98.
# 2. Наибольшим весом для модели обладают признаки: 'time_interval' (значение времени (в секундах) между началом и окончанием нагрева), 'temperature_begin' (начальная температура), 'time' (время (в секундах) между началом и окончанием нагрева температуры). Сильную связь признаков 'time_interval' и 'temperature_begin' с целевым признаком ('temperature_end') можно объяснить тем, что они являются частью единого процесса нагрева стали.

# ## Формирование обших выводов и рекомендаций для заказчика

# В ходе работы были проанализированы данные, предоставленные металлургическим комбинатом «Стальная птица», который хочет разработать модель, позволяющую определить конечную температуру сплава.
# 
# Для реализации этой задачи было выполнено 7 этапов работы.
# 
# На **1 этапе: Загрузка и изучение данных** были проанализированы все исходные данные, которые хранятся в 7 файлах, и выделены следующие наблюдения:
# 1. Данные во всех семи таблицах соответствую описанию задачи.
# 2. В пяти из семитаблицах с данными в столбцах присутствуют пропуски, некоторые из которых необходимо обработать. Также в некоторых таблицах необходимо изменить тип данных некоторых столбцов.
# 3. Во всех таблицах необходимо привести названия столбцов к общепринятому "змеиному" стилю.
# 4. Также стоит отметить, что при первичном изучении данных было выяснено, что таблицы 'data_bulk_time_new' и 'data_wire_time_new' содержать информацию о времени подачи различных видов материалов. Эти данные не имеют ценности для дальнейшего анализа. Поэтому уже на первом этапе эти таблицы с данными будут отброшены и не будут использоваться при дальнейшей обработке и реализации проекта, что в том числе сократит время выполнения задачи.
# 
# На **2 этапе: Исследовательский анализ и предобработка данных** дктально были изучены 5 таблиц, а именно:
# 1. data_arc_new — данные об электродах;
# 2. data_bulk_new — данные о подаче сыпучих материалов (объём);
# 3. data_gas_new — данные о продувке сплава газом;
# 4. data_temp_new — результаты измерения температуры;
# 5. data_wire_new — данные о проволочных материалах (объём);
# 
# Две таблицы 'data_bulk_time_new — данные о подаче сыпучих материалов (время)' и 'data_wire_time_new — данные о проволочных материалах (время)' на следующих этапах участвовать не будут, т.к. были откинуты с точки зрения неинформативности для реализации задачи.
# 
# И сделаны следующие выводы:
# 1. Названия во всех таблицах приведены к общепринятому "змеиному" стилю.
# 2. Во всех таблицах отсутствуют явные дубликаты.
# 3. Пропуски в таблицах 'data_bulk_new' и 'data_wire_new' заполнены нулями.
# 4. В таблицах 'data_arc_new' и 'data_temp_new' обработаны аномалии в столбцах 'reactive_power' (реактивная мощность) и 'temperature_begin' (начальная температура) соответственно.
# 5. Рассчитаны новые признаки: 'power' (полная мощность, включающая в себя активную и реактивную мощности), 'time_interval' (время в секундах между началом и окончанием нагрева), 'all_bulk_zero' (столбец со значениями всех нулевых итераций по подаче материалов), 'temperature_begin' и 'temperature_end' (начальная и конечная температуры соответственно), 'time' (время в секундах между началом и окончанием нагрева температуры), 'all_wire_zero' (столбец со значениями всех нулевых итераций по подаче проволочных материалов).
# 
# На **3 этапе: Объединение данных** было реализовано следующее:
# 1. На данном этапе все 5 таблиц после предобработки были объединены в одну общую таблицу.
# 2. Также были удалены столбцы, которые не являются информативными для исследования, а именно вся необходимая инфрмация из них содержится в других столбцах.
# 3. Пропуски и явные дубликаты в полученной таблице отсутствуют.
# 
# На **4 этапе: Исследовательский анализ и предобработка данных объединенного датафрейма** были получены следующие результаты:
# 1. Все признаки нового датафрейма корректно обработаны, присутствуют выбросы, но они не относятся к аномалиям, т.к. являются частью производственного процесса.
# 2. Зависимость целевого признака ('temperature_end' (значение конечной температуры)) с отстальными достаточно низкая, значения коэффициента корреляции колеблется возле нуля.
# 3. Связь между признаками 'power' (полная мощность) и 'time_interval' (значение времени (в секундах) между началом и окончанием нагрева) линейная и сильная, это подтверждает полученные коэффициент корреляции, равный 0.72.
# 4. Мультиколлинеарность между входными признаками не наблюдается.
# 
# На **5 этапе: Подготовка данных** было реализовано следующее:
# 1. 1. Данные разбиты на тренировочную и тестовую выборки, 75% и 25% соответственно.
# 2. Полученные размерности выборок соответствуют действительности.
# 
# На **6 этапе: Обучение моделей машинного обучения** было рассмотрено:
# 
# На данном этапе модели будут обучаться с помощью тренировочной и валидационной выборок, тестовая выборка будет использоваться только один раз при проверке качества лучшей модели.
# 
# Будут использоваться следующие модели:
# 1. LinearRegression (для этой модели будет реализовано масштабирование данных);
# 2. DecisionTreeRegressor (для этой модели будет реализован подбор гиперпараметров);
# 3. CatBoostRegressor (для этой модели будут фиксированные параметры);
# 4. LightGBM (для этой модели будут фиксированные параметры).
# 
# И получены следующие результаты:
# 1. По метрике оценки качества МАЕ, которая по условию задачи должна быть меньше 6.8, лучше всего себя показала модель: CatBoostRegressor.
# 2. Самой быстрой по сравнению с другими и подходящей по критериям для метрики оценки качества оказалась модель: LinearRegression. Однако результаты ее метрики качества оказали ниже, чем у CatBoostRegressor.
# 3. Модель DecisionTreeRegressor как с гиперпараметрами, так и без них, показала наихудший результат, не подходящий под критерий от заказчика, по метрике оценки качества МАЕ. Однако стоит отметить, что модель DecisionTreeRegressor (с гиперпараметрами) оказалась самой быстрой по времени обучения и предсказания среди всех рассматриваемых моделей.
# 
# На **7 этапе: Выбор лучшей модели и проверка ее качества на тестовой выборке** были сделаны выводы о том, что:
# 1. Лучшей моделью по метрике оценки качества МАЕ оказалась CatBoostRegressor (МАЕ = 5.89 на кросс-валидации), она удовлетворяет условию заказчика, что МАЕ должна быть не выше 6.8. Значение метрики качества МАЕ модели на **тестовой выборке** составило 5.98.
# 2. Наибольшим весом для модели обладают признаки: 'time_interval' (значение времени (в секундах) между началом и окончанием нагрева), 'temperature_begin' (начальная температура), 'time' (время (в секундах) между началом и окончанием нагрева температуры). Сильную связь признаков 'time_interval' и 'temperature_begin' с целевым признаком ('temperature_end') можно объяснить тем, что они являются частью единого процесса нагрева стали.
# 
# **Таким образом,** анализируя всю полученную в ходе исследования информацию, можно сделать вывод, что наилучшей моделью для предсказания конечной температуры сплава является CatBoostRegressor (с результатами МАЕ = 5.98 на тестовой выборке), так как заказчику важно, чтобы метрика оценки качества МАЕ была **не выше 6.8.**
